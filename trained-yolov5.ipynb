{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2581388,"sourceType":"datasetVersion","datasetId":901402}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -rf yolov5  # Remove the incomplete directory\n!git clone https://github.com/ultralytics/yolov5\n# !cd yolov5\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:14:22.263609Z","iopub.execute_input":"2025-01-12T12:14:22.263809Z","iopub.status.idle":"2025-01-12T12:14:24.021069Z","shell.execute_reply.started":"2025-01-12T12:14:22.263783Z","shell.execute_reply":"2025-01-12T12:14:24.019810Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 17120, done.\u001b[K\nremote: Counting objects: 100% (77/77), done.\u001b[K\nremote: Compressing objects: 100% (59/59), done.\u001b[K\nremote: Total 17120 (delta 47), reused 22 (delta 18), pack-reused 17043 (from 2)\u001b[K\nReceiving objects: 100% (17120/17120), 15.78 MiB | 31.44 MiB/s, done.\nResolving deltas: 100% (11746/11746), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd yolov5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:14:54.894608Z","iopub.execute_input":"2025-01-12T12:14:54.894935Z","iopub.status.idle":"2025-01-12T12:14:54.901262Z","shell.execute_reply.started":"2025-01-12T12:14:54.894910Z","shell.execute_reply":"2025-01-12T12:14:54.900455Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# import shutil\n# import os\n\n# # Path to the Kaggle working directory\n# output_path = \"/kaggle/working/\"\n\n# # Clear all files and folders in the output directory\n# for filename in os.listdir(output_path):\n#     file_path = os.path.join(output_path, filename)\n#     try:\n#         if os.path.isfile(file_path) or os.path.islink(file_path):\n#             os.unlink(file_path)  # Remove file or symlink\n#         elif os.path.isdir(file_path):\n#             shutil.rmtree(file_path)  # Remove directory\n#     except Exception as e:\n#         print(f\"Failed to delete {file_path}. Reason: {e}\")\n\n# print(\"Output directory cleared.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T06:56:21.310247Z","iopub.execute_input":"2025-01-12T06:56:21.310647Z","iopub.status.idle":"2025-01-12T06:56:21.450870Z","shell.execute_reply.started":"2025-01-12T06:56:21.310620Z","shell.execute_reply":"2025-01-12T06:56:21.449645Z"}},"outputs":[{"name":"stdout","text":"Output directory cleared.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"!pip install -r /kaggle/working/yolov5/requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:15:01.049906Z","iopub.execute_input":"2025-01-12T12:15:01.050190Z","iopub.status.idle":"2025-01-12T12:15:06.641194Z","shell.execute_reply.started":"2025-01-12T12:15:01.050168Z","shell.execute_reply":"2025-01-12T12:15:06.640205Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 5)) (3.1.43)\nRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 6)) (3.7.1)\nRequirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 8)) (4.10.0.84)\nRequirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 9)) (10.4.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 10)) (5.9.5)\nRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 11)) (6.0.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 12)) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 13)) (1.13.1)\nCollecting thop>=0.1.1 (from -r /kaggle/working/yolov5/requirements.txt (line 14))\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 15)) (2.4.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 16)) (0.19.1+cu121)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 17)) (4.66.5)\nCollecting ultralytics>=8.2.34 (from -r /kaggle/working/yolov5/requirements.txt (line 18))\n  Downloading ultralytics-8.3.59-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 27)) (2.1.4)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 28)) (0.12.2)\nRequirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/yolov5/requirements.txt (line 42)) (71.0.4)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r /kaggle/working/yolov5/requirements.txt (line 5)) (4.0.11)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /kaggle/working/yolov5/requirements.txt (line 6)) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /kaggle/working/yolov5/requirements.txt (line 6)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /kaggle/working/yolov5/requirements.txt (line 6)) (4.53.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /kaggle/working/yolov5/requirements.txt (line 6)) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /kaggle/working/yolov5/requirements.txt (line 6)) (24.1)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /kaggle/working/yolov5/requirements.txt (line 6)) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /kaggle/working/yolov5/requirements.txt (line 6)) (2.8.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r /kaggle/working/yolov5/requirements.txt (line 12)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r /kaggle/working/yolov5/requirements.txt (line 12)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r /kaggle/working/yolov5/requirements.txt (line 12)) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r /kaggle/working/yolov5/requirements.txt (line 12)) (2024.8.30)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /kaggle/working/yolov5/requirements.txt (line 15)) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /kaggle/working/yolov5/requirements.txt (line 15)) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /kaggle/working/yolov5/requirements.txt (line 15)) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /kaggle/working/yolov5/requirements.txt (line 15)) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /kaggle/working/yolov5/requirements.txt (line 15)) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /kaggle/working/yolov5/requirements.txt (line 15)) (2024.6.1)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r /kaggle/working/yolov5/requirements.txt (line 18)) (9.0.0)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r /kaggle/working/yolov5/requirements.txt (line 18))\n  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r /kaggle/working/yolov5/requirements.txt (line 27)) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r /kaggle/working/yolov5/requirements.txt (line 27)) (2024.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r /kaggle/working/yolov5/requirements.txt (line 5)) (5.0.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r /kaggle/working/yolov5/requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r /kaggle/working/yolov5/requirements.txt (line 15)) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r /kaggle/working/yolov5/requirements.txt (line 15)) (1.3.0)\nDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nDownloading ultralytics-8.3.59-py3-none-any.whl (906 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m906.8/906.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, thop, ultralytics\nSuccessfully installed thop-0.1.1.post2209072238 ultralytics-8.3.59 ultralytics-thop-2.0.13\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Paths\ndataset_path = \"/kaggle/input/cholecseg8k\"\noutput_path = \"/kaggle/working/\"\n\n# Define class mapping (adjust as per dataset)\nclass_mapping = {\n    \"background\": 0,\n    \"abdominal_wall\": 1,\n    \"liver\": 2,\n    \"gastrointestinal_tract\": 3,\n    \"fat\": 4,\n    \"grasper\": 5,\n    \"connective_tissue\": 6,\n    \"blood\": 7,\n    \"cystic_duct\": 8,\n    \"L_hook_electrocautery\": 9,\n    \"gallbladder\": 10,\n    \"hepatic_vein\": 11,\n    \"liver_ligament\": 12,\n}\n\n# Ensure output directories exist\nos.makedirs(os.path.join(output_path, \"images/train\"), exist_ok=True)\nos.makedirs(os.path.join(output_path, \"images/val\"), exist_ok=True)\nos.makedirs(os.path.join(output_path, \"labels/train\"), exist_ok=True)\nos.makedirs(os.path.join(output_path, \"labels/val\"), exist_ok=True)\n\n# Helper function to convert bounding boxes to YOLO format\ndef convert_bbox(image_size, bbox):\n    dw = 1.0 / image_size[1]\n    dh = 1.0 / image_size[0]\n    x = (bbox[0] + bbox[2]) / 2.0\n    y = (bbox[1] + bbox[3]) / 2.0\n    w = bbox[2] - bbox[0]\n    h = bbox[3] - bbox[1]\n    return x * dw, y * dh, w * dw, h * dh\n\n# Function to parse annotation masks and extract bounding boxes\ndef parse_annotations(annotation_path, class_mapping):\n    mask = cv2.imread(annotation_path, cv2.IMREAD_GRAYSCALE)\n    bboxes = []\n    for class_name, class_id in class_mapping.items():\n        # Extract binary mask for the class\n        class_mask = (mask == class_id).astype(np.uint8)\n        # Find contours (bounding boxes) for the class\n        contours, _ = cv2.findContours(class_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        for contour in contours:\n            x, y, w, h = cv2.boundingRect(contour)\n            if w > 0 and h > 0:  # Avoid zero-area boxes\n                bboxes.append({\"class_id\": class_id, \"bbox\": [x, y, x + w, y + h]})\n    return bboxes\n\n# Collect all image paths and corresponding annotation paths\nimage_paths = []\nannotation_paths = []\nfor video_dir in os.listdir(dataset_path):\n    video_path = os.path.join(dataset_path, video_dir)\n    for frame_dir in os.listdir(video_path):\n        frame_path = os.path.join(video_path, frame_dir)\n        for file in os.listdir(frame_path):\n            if file.endswith(\"_endo.png\"):  # Raw image\n                img_path = os.path.join(frame_path, file)\n                annotation_file = file.replace(\"_endo.png\", \"_endo_mask.png\")\n                annotation_path = os.path.join(frame_path, annotation_file)\n                \n                if os.path.exists(annotation_path):\n                    image_paths.append(img_path)\n                    annotation_paths.append(annotation_path)\n\n# Perform train-test split (80% train, 20% val)\ntrain_images, val_images, train_annotations, val_annotations = train_test_split(\n    image_paths, annotation_paths, test_size=0.2, random_state=42\n)\n\n# Process images and annotations for train and val sets\ndef process_dataset(image_paths, annotation_paths, split):\n    for img_path, annotation_path in zip(image_paths, annotation_paths):\n        # Load image and annotation\n        img = cv2.imread(img_path)\n        if img is None:\n            print(f\"Failed to load image: {img_path}\")\n            continue\n\n        height, width, _ = img.shape\n        bboxes = parse_annotations(annotation_path, class_mapping)\n\n        # Skip if no bounding boxes found\n        if not bboxes:\n            print(f\"No bounding boxes found for: {annotation_path}\")\n            continue\n\n        # Write labels to YOLO format\n        label_file = os.path.splitext(os.path.basename(img_path))[0] + \".txt\"\n        label_path = os.path.join(output_path, f\"labels/{split}\", label_file)\n        with open(label_path, \"w\") as f:\n            for bbox in bboxes:\n                class_id = bbox[\"class_id\"]\n                x, y, w, h = convert_bbox((height, width), bbox[\"bbox\"])\n                f.write(f\"{class_id} {x} {y} {w} {h}\\n\")\n\n        # Copy image to output folder\n        output_img_path = os.path.join(output_path, f\"images/{split}\", os.path.basename(img_path))\n        cv2.imwrite(output_img_path, img)\n\n# Process train and val datasets\nprocess_dataset(train_images, train_annotations, \"train\")\nprocess_dataset(val_images, val_annotations, \"val\")\n\nprint(\"Dataset preparation completed!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:15:14.389223Z","iopub.execute_input":"2025-01-12T12:15:14.389840Z","iopub.status.idle":"2025-01-12T12:23:16.234264Z","shell.execute_reply.started":"2025-01-12T12:15:14.389791Z","shell.execute_reply":"2025-01-12T12:23:16.233491Z"}},"outputs":[{"name":"stdout","text":"Dataset preparation completed!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Save the modified cholecseg8k.yaml file in the Kaggle working directory\ndataset_yaml = \"\"\"\ntrain: /kaggle/working/images/train\nval: /kaggle/working/images/val\n\nnc: 13  # Number of classes\nnames: ['background', 'abdominal_wall', 'liver', 'gastrointestinal_tract', 'fat', 'grasper', 'connective_tissue',\n        'blood', 'cystic_dut', 'L_hook_electrocautery', 'gallbladder', 'hepatic_vein', 'liver_ligament']\n\"\"\"\n\n# Write the YAML content to a file\nwith open('/kaggle/working/cholecseg8k.yaml', 'w') as yaml_file:\n    yaml_file.write(dataset_yaml)\n\nprint(\"YAML file saved successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:26:21.481662Z","iopub.execute_input":"2025-01-12T12:26:21.482116Z","iopub.status.idle":"2025-01-12T12:26:21.487763Z","shell.execute_reply.started":"2025-01-12T12:26:21.482089Z","shell.execute_reply":"2025-01-12T12:26:21.486907Z"}},"outputs":[{"name":"stdout","text":"YAML file saved successfully.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\n\n# Disable W&B visualization by setting the environment variable\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:26:26.959196Z","iopub.execute_input":"2025-01-12T12:26:26.959470Z","iopub.status.idle":"2025-01-12T12:26:26.963333Z","shell.execute_reply.started":"2025-01-12T12:26:26.959449Z","shell.execute_reply":"2025-01-12T12:26:26.962260Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!python train.py --img 640 --batch 16 --epochs 25 --data /kaggle/working/cholecseg8k.yaml --weights yolov5s.pt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T12:29:03.812286Z","iopub.execute_input":"2025-01-12T12:29:03.812662Z","iopub.status.idle":"2025-01-12T13:17:53.056020Z","shell.execute_reply.started":"2025-01-12T12:29:03.812629Z","shell.execute_reply":"2025-01-12T13:17:53.054889Z"}},"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n2025-01-12 12:29:09.482622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-01-12 12:29:09.504357: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-01-12 12:29:09.511560: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/kaggle/working/cholecseg8k.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\nYOLOv5 üöÄ v7.0-394-g86fd1ab2 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\nDownloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 18.4MB/s]\nDownloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.1M/14.1M [00:00<00:00, 151MB/s]\n\nOverriding model.yaml nc=80 with nc=13\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1     48546  models.yolo.Detect                      [13, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\nModel summary: 214 layers, 7054690 parameters, 7054690 gradients, 16.0 GFLOPs\n\nTransferred 343/349 items from yolov5s.pt\n/kaggle/working/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with amp.autocast(autocast):\n/kaggle/working/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with amp.autocast(autocast):\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\nWARNING ‚ö†Ô∏è DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\nSee Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/labels/train... 3567 images, 0 backgrounds, 0 co\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/labels/train.cache\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/labels/val... 1288 images, 0 backgrounds, 0 corrup\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/labels/val.cache\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.50 anchors/target, 0.842 Best Possible Recall (BPR). Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ‚ö†Ô∏è Extremely small objects found: 41159 of 245990 labels are <3 pixels in size\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 229475 points...\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7751: 100%|‚ñà‚ñà‚ñà‚ñà\u001b[0m\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9340 best possible recall, 1.93 anchors past thr\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.158/0.741-mean/best, past_thr=0.599-mean: 4,4, 9,8, 66,29, 70,147, 249,72, 229,154, 459,162, 254,326, 605,378\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ‚úÖ (optional: update model *.yaml to use these anchors in the future)\nPlotting labels to runs/train/exp/labels.jpg... \n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/kaggle/working/yolov5/train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=amp)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/exp\u001b[0m\nStarting training for 25 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n  0%|          | 0/223 [00:00<?, ?it/s]/kaggle/working/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(amp):\n       0/24      1.87G     0.1329    0.07412    0.07229       1286        640:  /kaggle/working/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(amp):\n       0/24      1.93G      0.101    0.09662    0.04374       1101        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.252     0.0294     0.0272     0.0183\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/24      2.39G    0.08508    0.09687    0.01798        870        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.431     0.0387     0.0354     0.0191\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/24      2.39G    0.08113    0.09163    0.01178       1417        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.542     0.0433     0.0543     0.0258\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/24      2.39G    0.07619    0.08952   0.009031       1126        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.511     0.0495     0.0593     0.0416\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/24      2.39G    0.07292    0.08842   0.007784       1095        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.494     0.0535      0.137     0.0753\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/24      2.39G    0.07088    0.08676   0.007025       2304        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.482     0.0545      0.176      0.106\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/24      2.39G     0.0692    0.08486   0.006419       1665        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.385     0.0747      0.197      0.121\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/24      2.39G    0.06789    0.08432   0.006052       1217        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.392     0.0768      0.201      0.128\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/24      2.39G    0.06661    0.08546   0.005778       1033        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.389     0.0768      0.196      0.124\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/24      2.39G    0.06566      0.084   0.005401       2152        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.382     0.0774      0.207       0.13\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/24      2.39G    0.06527    0.08353    0.00506       1379        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.354      0.226      0.205      0.132\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/24      2.39G    0.06434    0.08291   0.004919       1204        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.397      0.204      0.183      0.109\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/24      2.39G    0.06376    0.08284   0.004798       2005        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.875      0.188        0.2      0.127\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/24      2.39G    0.06293    0.08217   0.004642       1437        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.903      0.187      0.195      0.119\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/24      2.39G    0.06258    0.08109   0.004513       1164        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.467      0.202      0.212      0.138\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/24      2.39G      0.062    0.08174   0.004213        923        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.446      0.206      0.207       0.12\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/24      2.39G     0.0615    0.08096   0.004094       1454        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.452      0.207      0.211      0.139\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/24      2.39G    0.06098    0.07929     0.0039       1889        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.524      0.202      0.213       0.14\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/24      2.39G    0.06056    0.07899   0.003807       1772        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.532      0.202      0.214      0.134\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/24      2.39G    0.06009    0.07895   0.003705       1356        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.458      0.207      0.213      0.148\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      20/24      2.39G    0.05958      0.079   0.003684       1737        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.492      0.207      0.216      0.151\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      21/24      2.39G    0.05917    0.07783   0.003512       1803        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.484      0.208      0.215      0.147\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      22/24      2.39G    0.05871     0.0772   0.003384       1529        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.522      0.207      0.216       0.14\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      23/24      2.39G    0.05849    0.07625    0.00338       1363        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.547      0.205      0.216       0.15\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      24/24      2.39G    0.05812    0.07553   0.003273       1280        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889       0.52      0.208      0.217      0.148\n\n25 epochs completed in 0.783 hours.\nOptimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\nOptimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n\nValidating runs/train/exp/weights/best.pt...\nFusing layers... \nModel summary: 157 layers, 7045186 parameters, 0 gradients, 15.9 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1288      87889      0.493      0.207      0.216      0.152\n            background       1288      13504      0.675      0.155      0.174      0.146\n               grasper       1288         46      0.843      0.565      0.568      0.401\n          hepatic_vein       1288      37120      0.198     0.0503     0.0563     0.0273\n        liver_ligament       1288      37219      0.254     0.0558     0.0644     0.0329\nResults saved to \u001b[1mruns/train/exp\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}